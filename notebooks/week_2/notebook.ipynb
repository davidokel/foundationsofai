{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing and geometry in a feature space\n",
    "\n",
    "This coursework is designed to practically explore the content given in the lectures in week 3.\n",
    "\n",
    "## Hints\n",
    "\n",
    "- This one is a lot more challenging than last week so don't panic, break everything down into small steps\n",
    "\n",
    "- For the further work questions it may be helpful to write your code using functions rather than scripts (or even classes if they are familiar to you)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "import numpy as np\n",
    "#DO NOT CHANGE THIS CODE\n",
    "X_train=np.loadtxt('./data/X_train_linear.txt')\n",
    "X_test=np.loadtxt('./data/X_test_linear.txt')\n",
    "y_train=np.loadtxt('./data/y_train_linear.txt')\n",
    "y_test=np.loadtxt('./data/y_test_linear.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Geometry in a kernel-defined feature space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) Compute the linear kernel of the linear training data without centering the data and calculate the norm of the mean of a sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "linear_kernel = metrics.pairwise.linear_kernel(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) Calculate the expected squared distance to the mean of a sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.232934388541363\n"
     ]
    }
   ],
   "source": [
    "diagonals = np.diag(linear_kernel)\n",
    "kernel_average = np.mean(linear_kernel)\n",
    "expected_squared_distance = np.mean(diagonals) - kernel_average\n",
    "print(expected_squared_distance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c) By subtracting the appropriate matrix, implement the centering of this kernel matrix and verify that the norm of the mean of a sample is zero"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "1.022044671117328e-16"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "\n",
    "centered_kernel = KernelCenterer().fit_transform(linear_kernel)\n",
    "\n",
    "np.mean(centered_kernel)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d) Verify that the expected squared distance to the mean of a sample with the centred kernel is the same as the uncentred kernel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.232934388541363\n",
      "19.232934388541363\n"
     ]
    }
   ],
   "source": [
    "print(expected_squared_distance)\n",
    "diagonals = np.diag(centered_kernel)\n",
    "kernel_average = np.mean(centered_kernel)\n",
    "expected_squared_distance = np.mean(diagonals) - kernel_average\n",
    "print(expected_squared_distance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### e) By centering the original data and computing the linear kernel representation of the centered data show that the kernel representations are equivalent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Simple Classification Algorithm\n",
    "In this part we will build the simple classifier described in the lectures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#DO NOT CHANGE THIS CODE\n",
    "X_train=np.loadtxt('./data/X_train_poly.txt')\n",
    "X_test=np.loadtxt('./data/X_test_poly.txt')\n",
    "y_train=np.loadtxt('./data/y_train_poly.txt')\n",
    "y_test=np.loadtxt('./data/y_test_poly.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) Write a function which calculates the mean of the kernel function of a sample with the positive and negative training data (i.e. the terms that aren't b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "def calc_mean(kernel):\n",
    "    return np.mean(kernel)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) Write a function which calculates the b term in the simple classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c) Write the decision function of the classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c) Calculate the accuracy of this simple classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Fisher Discriminant Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) Write a function which calculates the matrices B, C, and D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) Write a function which calculates the dual variables for the FDA classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c) Write a function which calculates t and therefore the offset term b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d) Write the decision function of the classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Further Investigation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) For one or both classifiers Demonstrate how the performance of the classifier changes if one class is overrepresented in the training data as compared to the test data (i.e. there are imbalanced classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) Demonstrate how regularisation can be used to improve the generalisation of the FDA classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
